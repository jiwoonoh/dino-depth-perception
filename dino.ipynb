{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ViTImageProcessor, ViTModel\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1229\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/utils/import_utils.py:1163\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[39melif\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_class_to_module\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m   1162\u001b[0m     module \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_module(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_class_to_module[name])\n\u001b[0;32m-> 1163\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1164\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1165\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodule \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m has no attribute \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/utils/import_utils.py:1162\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1160\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_module(name)\n\u001b[1;32m   1161\u001b[0m \u001b[39melif\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_class_to_module\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m-> 1162\u001b[0m     module \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_module(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_class_to_module[name])\n\u001b[1;32m   1163\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1164\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/utils/import_utils.py:1172\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1170\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_module\u001b[39m(\u001b[39mself\u001b[39m, module_name: \u001b[39mstr\u001b[39m):\n\u001b[1;32m   1171\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1172\u001b[0m         \u001b[39mreturn\u001b[39;00m importlib\u001b[39m.\u001b[39mimport_module(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m module_name, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m   1173\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1174\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1175\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to import \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mmodule_name\u001b[39m}\u001b[39;00m\u001b[39m because of the following error (look up to see its\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1176\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m traceback):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1177\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/vit/image_processing_vit.py:22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimage_processing_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseImageProcessor, BatchFeature, get_size_dict\n\u001b[0;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimage_transforms\u001b[39;00m \u001b[39mimport\u001b[39;00m normalize, rescale, resize, to_channel_dimension_format\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimage_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     24\u001b[0m     IMAGENET_STANDARD_MEAN,\n\u001b[1;32m     25\u001b[0m     IMAGENET_STANDARD_STD,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     valid_images,\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m TensorType, logging\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/image_transforms.py:45\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mimage_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m PILImageResampling\n\u001b[1;32m     44\u001b[0m \u001b[39mif\u001b[39;00m is_torch_available():\n\u001b[0;32m---> 45\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[39mif\u001b[39;00m is_tf_available():\n\u001b[1;32m     48\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/__init__.py:1247\u001b[0m\n\u001b[1;32m   1245\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m testing \u001b[39mas\u001b[39;00m testing\n\u001b[1;32m   1246\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackends\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcuda\u001b[39;00m\n\u001b[0;32m-> 1247\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackends\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmps\u001b[39;00m\n\u001b[1;32m   1248\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackends\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcudnn\u001b[39;00m\n\u001b[1;32m   1249\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackends\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmkl\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/backends/mps/__init__.py:30\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mif\u001b[39;00m is_built():\n\u001b[1;32m     29\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlibrary\u001b[39;00m \u001b[39mimport\u001b[39;00m Library \u001b[39mas\u001b[39;00m _Library\n\u001b[0;32m---> 30\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_refs\u001b[39;00m \u001b[39mimport\u001b[39;00m var_mean \u001b[39mas\u001b[39;00m _var_mean, native_group_norm \u001b[39mas\u001b[39;00m _native_group_norm\n\u001b[1;32m     31\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_decomp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdecompositions\u001b[39;00m \u001b[39mimport\u001b[39;00m native_group_norm_backward \u001b[39mas\u001b[39;00m _native_group_norm_backward\n\u001b[1;32m     32\u001b[0m     _lib \u001b[39m=\u001b[39m _Library(\u001b[39m\"\u001b[39m\u001b[39maten\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mIMPL\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_refs/__init__.py:14\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Callable, List, Optional, overload, Sequence, Tuple, Union\n\u001b[1;32m     12\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_prims\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mprims\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_prims_common\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mutils\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m sym_float, sym_int\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_prims/__init__.py:33\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_prims_common\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     18\u001b[0m     check,\n\u001b[1;32m     19\u001b[0m     Dim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m     type_to_dtype,\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_prims_common\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mwrappers\u001b[39;00m \u001b[39mimport\u001b[39;00m backwards_not_supported\n\u001b[0;32m---> 33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_subclasses\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfake_tensor\u001b[39;00m \u001b[39mimport\u001b[39;00m FakeTensor, FakeTensorMode\n\u001b[1;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moverrides\u001b[39;00m \u001b[39mimport\u001b[39;00m handle_torch_function, has_torch_function\n\u001b[1;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_pytree\u001b[39;00m \u001b[39mimport\u001b[39;00m tree_flatten, tree_map, tree_unflatten\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_subclasses/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_subclasses\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfake_tensor\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      4\u001b[0m     DynamicOutputShapeException,\n\u001b[1;32m      5\u001b[0m     FakeTensor,\n\u001b[1;32m      6\u001b[0m     FakeTensorMode,\n\u001b[1;32m      7\u001b[0m     UnsupportedFakeTensorException,\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_subclasses\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfake_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m CrossRefFakeMode\n\u001b[1;32m     12\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[1;32m     13\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mFakeTensor\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mFakeTensorMode\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mCrossRefFakeMode\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     18\u001b[0m ]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py:22\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_prims_common\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m     elementwise_dtypes,\n\u001b[1;32m     17\u001b[0m     ELEMENTWISE_TYPE_PROMOTION_KIND,\n\u001b[1;32m     18\u001b[0m     is_float_dtype,\n\u001b[1;32m     19\u001b[0m     is_integer_dtype,\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_subclasses\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmeta_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m MetaConverter\n\u001b[0;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfx\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moperator_schemas\u001b[39;00m \u001b[39mimport\u001b[39;00m normalize_function\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmultiprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreductions\u001b[39;00m \u001b[39mimport\u001b[39;00m StorageWeakRef\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moverrides\u001b[39;00m \u001b[39mimport\u001b[39;00m TorchFunctionMode\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/fx/__init__.py:84\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mr\u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mFX is a toolkit for developers to use to transform ``nn.Module``\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39minstances. FX consists of three main components: a **symbolic tracer,**\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[39mrepository.\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mgraph_module\u001b[39;00m \u001b[39mimport\u001b[39;00m GraphModule\n\u001b[0;32m---> 84\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_symbolic_trace\u001b[39;00m \u001b[39mimport\u001b[39;00m symbolic_trace, Tracer, wrap, PH, ProxyableClassMeta\n\u001b[1;32m     85\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mgraph\u001b[39;00m \u001b[39mimport\u001b[39;00m Graph, CodeGen\n\u001b[1;32m     86\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mnode\u001b[39;00m \u001b[39mimport\u001b[39;00m Node, map_arg\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/fx/_symbolic_trace.py:48\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_fx_tracing\u001b[39m():\n\u001b[1;32m     46\u001b[0m     \u001b[39mreturn\u001b[39;00m _is_fx_tracing_flag\n\u001b[0;32m---> 48\u001b[0m \u001b[39m@compatibility\u001b[39m(is_backward_compatible\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     49\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mProxyableClassMeta\u001b[39;00m(\u001b[39mtype\u001b[39m):\n\u001b[1;32m     50\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[39m    ProxyableClassMeta allows you to make construction of a given Python class\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[39m    symbolically traceable. For example::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39m    tracing.\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mcls\u001b[39m, name, bases, attrs):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/fx/_compatibility.py:11\u001b[0m, in \u001b[0;36mcompatibility.<locals>.mark_back_compat\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[39mdef\u001b[39;00m \u001b[39mmark_back_compat\u001b[39m(fn):\n\u001b[0;32m---> 11\u001b[0m             docstring \u001b[39m=\u001b[39m textwrap\u001b[39m.\u001b[39mdedent(\u001b[39mgetattr\u001b[39m(fn, \u001b[39m'\u001b[39m\u001b[39m__doc__\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mor\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m             docstring \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[39m.. note::\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[39m    Backwards-compatibility for this API is guaranteed.\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m     16\u001b[0m             fn\u001b[39m.\u001b[39m\u001b[39m__doc__\u001b[39m \u001b[39m=\u001b[39m docstring\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/textwrap.py:466\u001b[0m, in \u001b[0;36mdedent\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m line \u001b[39mor\u001b[39;00m line\u001b[39m.\u001b[39mstartswith(margin), \\\n\u001b[1;32m    463\u001b[0m                \u001b[39m\"\u001b[39m\u001b[39mline = \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m, margin = \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (line, margin)\n\u001b[1;32m    465\u001b[0m \u001b[39mif\u001b[39;00m margin:\n\u001b[0;32m--> 466\u001b[0m     text \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m(?m)^\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m margin, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, text)\n\u001b[1;32m    467\u001b[0m \u001b[39mreturn\u001b[39;00m text\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/re/__init__.py:185\u001b[0m, in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msub\u001b[39m(pattern, repl, string, count\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, flags\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m    179\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the string obtained by replacing the leftmost\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[39m    non-overlapping occurrences of the pattern in string by the\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[39m    replacement repl.  repl can be either a string or a callable;\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[39m    if a string, backslash escapes in it are processed.  If it is\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[39m    a callable, it's passed the Match object and must return\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[39m    a replacement string to be used.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[39mreturn\u001b[39;00m _compile(pattern, flags)\u001b[39m.\u001b[39msub(repl, string, count)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import ViTImageProcessor, ViTModel\n",
    "from PIL import Image\n",
    "import torch\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm  # Import tqdm\n",
    "\n",
    "# Define the data directory and output file\n",
    "data_dir = \"data\"\n",
    "output_file = \"combined_features.pt\"\n",
    "\n",
    "# Load the ViT processor and model\n",
    "processor = ViTImageProcessor.from_pretrained('facebook/dino-vits16')\n",
    "model = ViTModel.from_pretrained('facebook/dino-vits16')\n",
    "\n",
    "# Initialize or load existing paired features if file exists\n",
    "if os.path.exists(output_file):\n",
    "    all_paired_features = torch.load(output_file)\n",
    "    print(f\"Loaded existing features from {output_file}\")\n",
    "else:\n",
    "    all_paired_features = []\n",
    "\n",
    "# Iterate through all numbered folders with tqdm for progress tracking\n",
    "for folder_num in tqdm(range(25), desc=\"Processing folders\"):\n",
    "    folder_path = os.path.join(data_dir, str(folder_num))\n",
    "    \n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue  # Skip if folder doesn't exist\n",
    "    \n",
    "    # Get all image files in the folder, sorted for sequential pairing\n",
    "    image_files = sorted(glob.glob(os.path.join(folder_path, \"*.png\")))\n",
    "    \n",
    "    # Track progress of image pairs processing with tqdm\n",
    "    for t in tqdm(range(len(image_files) - 1), desc=f\"Folder {folder_num}\", leave=False):\n",
    "        try:\n",
    "            # Load the images\n",
    "            image_t = Image.open(image_files[t])\n",
    "            image_t1 = Image.open(image_files[t + 1])\n",
    "            \n",
    "            # Preprocess the images\n",
    "            inputs_t = processor(images=image_t, return_tensors=\"pt\")\n",
    "            inputs_t1 = processor(images=image_t1, return_tensors=\"pt\")\n",
    "            \n",
    "            # Forward pass through the model\n",
    "            outputs_t = model(**inputs_t)\n",
    "            outputs_t1 = model(**inputs_t1)\n",
    "            \n",
    "            # Extract and reshape patch embeddings\n",
    "            patch_embeddings_t = outputs_t.last_hidden_state[:, 1:, :]\n",
    "            patch_embeddings_t1 = outputs_t1.last_hidden_state[:, 1:, :]\n",
    "            \n",
    "            batch_size, num_patches, hidden_dim = patch_embeddings_t.shape\n",
    "            h, w = int(num_patches**0.5), int(num_patches**0.5)  # Assume square grid\n",
    "            \n",
    "            reshaped_features_t = patch_embeddings_t.transpose(1, 2).reshape(batch_size, hidden_dim, h, w)\n",
    "            reshaped_features_t1 = patch_embeddings_t1.transpose(1, 2).reshape(batch_size, hidden_dim, h, w)\n",
    "            \n",
    "            # Combine the reshaped features for the pair\n",
    "            paired_features = torch.cat([reshaped_features_t, reshaped_features_t1], dim=0)  # Shape: [2, hidden_dim, h, w]\n",
    "            \n",
    "            # Append to the list of all paired features\n",
    "            all_paired_features.append(paired_features)\n",
    "            \n",
    "            # Save the current features to the file\n",
    "            torch.save(all_paired_features, output_file)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing images in folder {folder_num}, pair {t}: {e}\")\n",
    "            continue\n",
    "\n",
    "print(f\"Saved combined features to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTImageProcessor, ViTModel\n",
    "from PIL import Image\n",
    "import torch\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the data directory and output directory for .pt files\n",
    "data_dir = \"data\"\n",
    "output_dir = \"processed_pairs\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load the ViT processor and model\n",
    "processor = ViTImageProcessor.from_pretrained('facebook/dino-vits16')\n",
    "model = ViTModel.from_pretrained('facebook/dino-vits16')\n",
    "\n",
    "# Iterate through all numbered folders with tqdm for progress tracking\n",
    "for folder_num in tqdm(range(25), desc=\"Processing folders\"):\n",
    "    folder_path = os.path.join(data_dir, str(folder_num))\n",
    "    \n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue  # Skip if folder doesn't exist\n",
    "    \n",
    "    # Get all image files in the folder, sorted for sequential pairing\n",
    "    image_files = sorted(glob.glob(os.path.join(folder_path, \"*.png\")))\n",
    "    \n",
    "    # Process each pair of images\n",
    "    for image_idx in range(len(image_files) - 1):\n",
    "        try:\n",
    "            # Load the images\n",
    "            image_t_path = image_files[image_idx]\n",
    "            image_t1_path = image_files[image_idx + 1]\n",
    "            \n",
    "            image_t = Image.open(image_t_path)\n",
    "            image_t1 = Image.open(image_t1_path)\n",
    "            \n",
    "            # Preprocess the images\n",
    "            inputs_t = processor(images=image_t, return_tensors=\"pt\")\n",
    "            inputs_t1 = processor(images=image_t1, return_tensors=\"pt\")\n",
    "            \n",
    "            # Forward pass through the model\n",
    "            with torch.no_grad():\n",
    "                outputs_t = model(**inputs_t)\n",
    "                outputs_t1 = model(**inputs_t1)\n",
    "            \n",
    "            # Extract feature embeddings\n",
    "            patch_embeddings_t = outputs_t.last_hidden_state[:, 1:, :]\n",
    "            patch_embeddings_t1 = outputs_t1.last_hidden_state[:, 1:, :]\n",
    "            batch_size, num_patches, hidden_dim = patch_embeddings_t.shape\n",
    "            h, w = int(num_patches**0.5), int(num_patches**0.5)  # Assume square grid\n",
    "            \n",
    "            # Reshape and squeeze patch embeddings\n",
    "            reshaped_features_t = patch_embeddings_t.transpose(1, 2).reshape(batch_size, hidden_dim, h, w).squeeze(0)  # Shape: [384, 14, 14]\n",
    "            reshaped_features_t1 = patch_embeddings_t1.transpose(1, 2).reshape(batch_size, hidden_dim, h, w).squeeze(0)  # Shape: [384, 14, 14]\n",
    "            \n",
    "            # Squeeze the processed images\n",
    "            processed_image_t = inputs_t[\"pixel_values\"].squeeze(0)  # Shape: [3, 224, 224]\n",
    "            processed_image_t1 = inputs_t1[\"pixel_values\"].squeeze(0)  # Shape: [3, 224, 224]\n",
    "            \n",
    "            # Prepare the pair data as a dictionary\n",
    "            pair_data = {\n",
    "                \"image_t\": {\n",
    "                    \"image_path\": image_t_path,\n",
    "                    \"processed_image\": processed_image_t,\n",
    "                    \"feature_embedding\": reshaped_features_t\n",
    "                },\n",
    "                \"image_t1\": {\n",
    "                    \"image_path\": image_t1_path,\n",
    "                    \"processed_image\": processed_image_t1,\n",
    "                    \"feature_embedding\": reshaped_features_t1\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # Save the data as a .pt file\n",
    "            output_file = os.path.join(output_dir, f\"folder_{folder_num}_pair_{image_idx}.pt\")\n",
    "            torch.save(pair_data, output_file)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image pair ({image_t_path}, {image_t1_path}): {e}\")\n",
    "            continue\n",
    "\n",
    "print(f\"Processed image pairs and feature embeddings saved to {output_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fda69c70924b840e7fd5ea2c0ea0e3ecd9cf01233411f45a500a3e6a9b29d9bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
