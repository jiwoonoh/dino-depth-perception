{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import DictDataset, RepeatedDictDataset\n",
    "from model import *\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from importlib import reload\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import wandb\n",
    "import torch\n",
    "import os\n",
    "from loss_functions import *\n",
    "from inverse_warp import inverse_warp\n",
    "from utils import projective_inverse_warp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "# sample = dataloader.__iter__().__next__()\n",
    "# bigmodel = BigModel()\n",
    "# pose_final, depth_map = bigmodel(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeatdataset = RepeatedDictDataset('./data/folder_0_pair_0.pt', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def train_model(bigmodel, \n",
    "                train_dataset, \n",
    "                val_dataset, \n",
    "                num_epochs=10, \n",
    "                batch_size=2,\n",
    "                lr=1e-3,\n",
    "                device='cpu',\n",
    "                optimizer_cls=optim.Adam,\n",
    "                patience=3,\n",
    "                log_interval=10,\n",
    "                save_dir=\"models\",  # Directory to save the model\n",
    "                save_name=\"best_model.pth\"  # Model name to save\n",
    "                ):\n",
    "    \"\"\"\n",
    "    Train a model with photometric and smooth loss for depth estimation.\n",
    "    \"\"\"\n",
    "    # Camera intrinsics\n",
    "    intrinsics_flat = [9.569475e+02, 0.000000e+00, 6.939767e+02,\n",
    "                       0.000000e+00, 9.522352e+02, 2.386081e+02,\n",
    "                       0.000000e+00, 0.000000e+00, 1.000000e+00]\n",
    "\n",
    "    # Move the model to the device\n",
    "    bigmodel.to(device)\n",
    "\n",
    "    # Set up data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    optimizer = optimizer_cls(bigmodel.parameters(), lr=lr)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    # Ensure the save directory exists\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    save_path = os.path.join(save_dir, save_name)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        bigmodel.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        # Use tqdm for progress tracking\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        for i, sample in enumerate(progress_bar):\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Prepare inputs\n",
    "            B = sample['image_t1']['processed_image'].shape[0]  # Batch size\n",
    "            intrinsics_matrix = torch.tensor(intrinsics_flat).view(1, 3, 3).repeat(B, 1, 1).to(device)\n",
    "\n",
    "            tgt_image = sample['image_t1']['processed_image'].to(device)  # Target image [B, 3, H, W]\n",
    "            ref_image = sample['image_t']['processed_image'].to(device)  # Reference image [B, 3, H, W]\n",
    "\n",
    "            # Forward pass\n",
    "            pose, depth_map = bigmodel(sample)\n",
    "\n",
    "            # Ensure depth_map is [B, H, W]\n",
    "            if depth_map.dim() == 4:  # [B, 1, H, W]\n",
    "                depth_map = depth_map.squeeze(1)  # Remove channel dimension\n",
    "\n",
    "            # Photometric reconstruction loss\n",
    "            photometric_loss = photometric_reconstruction_loss(\n",
    "                tgt_img=tgt_image,\n",
    "                ref_img=ref_image,\n",
    "                intrinsics=intrinsics_matrix,\n",
    "                depth=depth_map,\n",
    "                pose=pose\n",
    "            )\n",
    "\n",
    "            # Smooth loss\n",
    "            smoothness_loss = smooth_loss(depth_map.unsqueeze(1))  # Add back channel dimension\n",
    "\n",
    "            # Total loss\n",
    "            loss = photometric_loss + 0.01 * smoothness_loss\n",
    "\n",
    "            # Backward pass and optimizer step\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate train loss\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            if i % log_interval == 0:\n",
    "                avg_loss = train_loss / (i + 1)\n",
    "                progress_bar.set_postfix(loss=avg_loss)\n",
    "\n",
    "        # Validation loop (optional, uncomment if needed)\n",
    "        # bigmodel.eval()\n",
    "        # val_loss = 0.0\n",
    "        # with torch.no_grad():\n",
    "        #     for sample in val_loader:\n",
    "        #         tgt_image = sample['image_t1']['processed_image'].to(device)\n",
    "        #         ref_image = sample['image_t']['processed_image'].to(device)\n",
    "        #         pose, depth_map = bigmodel(sample)\n",
    "        #         depth_map = depth_map.squeeze(1) if depth_map.dim() == 4 else depth_map\n",
    "        #         photometric_loss = photometric_reconstruction_loss(\n",
    "        #             tgt_img=tgt_image,\n",
    "        #             ref_img=ref_image,\n",
    "        #             intrinsics=intrinsics_matrix,\n",
    "        #             depth=depth_map,\n",
    "        #             pose=pose\n",
    "        #         )\n",
    "        #         smoothness_loss = smooth_loss(depth_map.unsqueeze(1))\n",
    "        #         val_loss += (photometric_loss + 0.01 * smoothness_loss).item()\n",
    "        #\n",
    "        # val_loss /= len(val_loader)\n",
    "        # if val_loss < best_val_loss:\n",
    "        #     best_val_loss = val_loss\n",
    "        #     patience_counter = 0\n",
    "        #     torch.save(bigmodel.state_dict(), save_path)\n",
    "        # else:\n",
    "        #     patience_counter += 1\n",
    "\n",
    "        # if patience_counter >= patience:\n",
    "        #     print(\"Early stopping triggered!\")\n",
    "        #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 50/50 [00:09<00:00,  5.53it/s, loss=4.26e-6]\n",
      "Epoch 2/10: 100%|██████████| 50/50 [00:08<00:00,  6.05it/s, loss=1.16e-7]\n",
      "Epoch 3/10: 100%|██████████| 50/50 [00:09<00:00,  5.45it/s, loss=1.94e-8]\n",
      "Epoch 4/10:  28%|██▊       | 14/50 [00:02<00:06,  5.29it/s, loss=4.42e-9]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m big \u001b[38;5;241m=\u001b[39m BigModel()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbigmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrepeatdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrepeatdataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 85\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(bigmodel, train_dataset, val_dataset, num_epochs, batch_size, lr, device, optimizer_cls, patience, log_interval, save_dir, save_name)\u001b[0m\n\u001b[1;32m     82\u001b[0m loss \u001b[38;5;241m=\u001b[39m photometric_loss \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.01\u001b[39m \u001b[38;5;241m*\u001b[39m smoothness_loss\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Backward pass and optimizer step\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Accumulate train loss\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/camera/lib/python3.11/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/camera/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/camera/lib/python3.11/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "big = BigModel()\n",
    "train_model(bigmodel = big,\n",
    "            train_dataset = repeatdataset,\n",
    "            val_dataset = repeatdataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
